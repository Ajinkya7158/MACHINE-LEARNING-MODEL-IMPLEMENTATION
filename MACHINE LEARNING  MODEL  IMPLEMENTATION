import re
import string
from collections import defaultdict

# Sample dataset with messages and labels (0 = ham, 1 = spam)
dataset = [
    {'label': 0, 'message': 'Hello, how are you doing today?'},
    {'label': 1, 'message': 'Congratulations! You won a prize. Click here to claim it!'},
    {'label': 0, 'message': 'Are you available for a meeting tomorrow?'},
    {'label': 1, 'message': 'Earn money fast by working from home! Join now.'},
    {'label': 0, 'message': 'Let me know if you are free this weekend.'},
    {'label': 1, 'message': 'Get your free iPhone today! Call now!'}
]

# Preprocessing text (removing punctuation, converting to lowercase, etc.)
def clean_text(text):
    text = text.lower()  # Convert text to lowercase
    text = re.sub(f"[{string.punctuation}]", "", text)  # Remove punctuation
    text = re.sub(r"\d+", "", text)  # Remove digits
    return text

# Preprocess the dataset
for entry in dataset:
    entry['message'] = clean_text(entry['message'])

# Split the data into training and test sets (80% train, 20% test)
train_size = int(0.8 * len(dataset))
train_data = dataset[:train_size]
test_data = dataset[train_size:]

# Create a vocabulary (a set of unique words) from the training data
vocabulary = set()
for entry in train_data:
    words = entry['message'].split()
    vocabulary.update(words)

# Convert vocabulary to a list for indexing
vocabulary = list(vocabulary)
word_to_index = {word: idx for idx, word in enumerate(vocabulary)}

# Create Bag of Words representation for training data
def create_bow(text, word_to_index):
    vector = [0] * len(word_to_index)
    for word in text.split():
        if word in word_to_index:
            vector[word_to_index[word]] += 1
    return vector

# Training the Naive Bayes model (from scratch)
def naive_bayes_train(train_data, word_to_index):
    # Initialize counts for spam and ham messages
    spam_word_counts = [0] * len(word_to_index)
    ham_word_counts = [0] * len(word_to_index)
    spam_count = 0
    ham_count = 0
    
    # Count the words in each category
    for entry in train_data:
        label = entry['label']
        word_vector = create_bow(entry['message'], word_to_index)
        
        if label == 1:  # Spam
            spam_count += 1
            for i in range(len(word_vector)):
                spam_word_counts[i] += word_vector[i]
        else:  # Ham
            ham_count += 1
            for i in range(len(word_vector)):
                ham_word_counts[i] += word_vector[i]
    
    total_words_spam = sum(spam_word_counts)
    total_words_ham = sum(ham_word_counts)
    
    # Calculate the prior probabilities
    p_spam = spam_count / len(train_data)
    p_ham = ham_count / len(train_data)
    
    # Calculate likelihoods (word probabilities given spam/ham)
    p_word_given_spam = [(count + 1) / (total_words_spam + len(vocabulary)) for count in spam_word_counts]
    p_word_given_ham = [(count + 1) / (total_words_ham + len(vocabulary)) for count in ham_word_counts]
    
    return p_spam, p_ham, p_word_given_spam, p_word_given_ham

# Train the Naive Bayes model
p_spam, p_ham, p_word_given_spam, p_word_given_ham = naive_bayes_train(train_data, word_to_index)

# Predicting with the Naive Bayes model (from scratch)
def naive_bayes_predict(test_data, p_spam, p_ham, p_word_given_spam, p_word_given_ham, word_to_index):
    predictions = []
    
    for entry in test_data:
        message = entry['message']
        word_vector = create_bow(message, word_to_index)
        
        # Calculate the log probabilities for spam and ham
        log_p_spam = p_spam
        log_p_ham = p_ham
        
        for i in range(len(word_vector)):
            log_p_spam += word_vector[i] * (p_word_given_spam[i])
            log_p_ham += word_vector[i] * (p_word_given_ham[i])
        
        # Compare the probabilities and predict
        if log_p_spam > log_p_ham:
            predictions.append(1)  # Spam
        else:
            predictions.append(0)  # Ham
    
    return predictions

# Make predictions on the test data
y_pred = naive_bayes_predict(test_data, p_spam, p_ham, p_word_given_spam, p_word_given_ham, word_to_index)

# Calculate accuracy
def calculate_accuracy(y_true, y_pred):
    correct = sum([1 for true, pred in zip(y_true, y_pred) if true == pred])
    accuracy = correct / len(y_true)
    return accuracy

# Calculate accuracy
y_true = [entry['label'] for entry in test_data]
accuracy = calculate_accuracy(y_true, y_pred)
print(f'Accuracy: {accuracy:.2f}')

